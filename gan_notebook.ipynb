{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dfee73",
   "metadata": {},
   "source": [
    "# GANs Image Generation\n",
    "\n",
    "In this notebook, we will explore how Generative Adversarial Networks (GANs) generate images. We will use a pretrained GAN model (BigGAN) to generate images from random noise.\n",
    "\n",
    "## Instructions\n",
    "1. Run the code below to generate an image from random noise.\n",
    "2. Modify the latent vector to generate different images.\n",
    "3. Experiment with generating different images by altering the latent vector and visualizing the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c1448e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from pytorch_pretrained_biggan import BigGAN, one_hot_from_int, truncated_noise_sample\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load pretrained BigGAN model\n",
    "model = BigGAN.from_pretrained('biggan-deep-256')\n",
    "model.eval()\n",
    "\n",
    "# Generate random latent vector (noise)\n",
    "latent_vector = torch.from_numpy(truncated_noise_sample(truncation=0.4, batch_size=1))\n",
    "\n",
    "# Create class vector (e.g., 207 = golden retriever)\n",
    "class_vector = torch.from_numpy(one_hot_from_int([207], batch_size=1))\n",
    "\n",
    "# Generate image\n",
    "with torch.no_grad():\n",
    "    generated_image = model(latent_vector, class_vector, truncation=0.4)\n",
    "\n",
    "# Convert the tensor to a displayable image\n",
    "generated_image = generated_image.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "generated_image = ((generated_image + 1) / 2.0 * 255).astype('uint8')\n",
    "img1 = Image.fromarray(generated_image)\n",
    "img1.save(\"image1_truncated.png\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0053511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different latent vectors\n",
    "latent_vector = torch.randn(1, 128)  # Change this to explore different random vectors\n",
    "with torch.no_grad():\n",
    "    generated_image = model(latent_vector, class_vector, truncation=0.4)\n",
    "generated_image = generated_image[0].permute(1, 2, 0).cpu().numpy()  # CHW â†’ HWC\n",
    "generated_image = ((generated_image + 1) / 2.0 * 255).astype('uint8')\n",
    "img2 = Image.fromarray(generated_image)\n",
    "img2.save(\"image2_random.png\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff7b1ff",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "- **How did the generated images change when you modified the latent vector?**  \n",
    "  The structure, clarity, and realism of the images changed significantly. Truncated vectors produced realistic dogs, while random vectors were more chaotic and distorted. Manual edits created abstract combinations.\n",
    "\n",
    "- **What patterns did you notice? Were they realistic?**  \n",
    "  Some outputs were surprisingly realistic, especially when using truncated noise. Common distortions included warped faces, unnatural limbs, and unclear backgrounds.\n",
    "\n",
    "- **How does generating from noise differ from traditional image creation?**  \n",
    "  Unlike rule-based or pixel-drawn images, GANs learn representations and generate content from noise without direct instructions. This makes outputs creative but unpredictable.\n",
    "\n",
    "- **What were the limitations or challenges?**  \n",
    "  It was hard to consistently control the outputs. Small changes in noise led to big visual differences. The model also occasionally generated unnatural, blended, or fragmented features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
